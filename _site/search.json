[
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nCOINr: An R package for developing composite indicators\n\n\nJournal of Open Source Software\n\n\n\n\nIndicators\n\n\nSoftware\n\n\n \n\n\n\n\nOct 11, 2022\n\n\nWilliam Becker, Giulio Caperna, Maria Del Sorbo, Hedvig Norlen, Eleni Papadimitriou, Michaela Saisana\n\n\n\n\n\n\n\n\nThe Water-Energy-Food Nexus Index: A Tool to Support Integrated Resource Planning, Management and Security\n\n\nFrontiers in Water\n\n\n\n\nIndicators\n\n\nWater\n\n\nPolicy\n\n\nSustainable development\n\n\n \n\n\n\n\nMar 10, 2022\n\n\nGareth Simpson, Graham Jewitt, William Becker, Jessica Badenhorst, Sara Masia, Ana Rita Neves, Pere Rovira, Victor Pascual\n\n\n\n\n\n\n\n\nExploring the link between Asia and Europe connectivity and sustainable development\n\n\nResearch in Globalization\n\n\n\n\nIndicators\n\n\nGlobalisation\n\n\nSustainable development\n\n\n \n\n\n\n\nDec 1, 2021\n\n\nWilliam Becker, Marcos Domínguez-Torreiro, Ana Neves, Carlos Tacao Moura, Michaela Saisana\n\n\n\n\n\n\n\n\nPolynomial chaos expansion for sensitivity analysis of model output with dependent inputs\n\n\nReliability Engineering & System Safety\n\n\n\n\nSensitivity analysis\n\n\nWater\n\n\nOptimisation\n\n\nMachine learning\n\n\n \n\n\n\n\nOct 1, 2021\n\n\nThierry Mara, William Becker\n\n\n\n\n\n\n\n\nA framework based on statistical analysis and stakeholders’ preferences to inform weighting in composite indicators\n\n\nEnvironmental Modelling and Software\n\n\n\n\nIndicators\n\n\nEnergy\n\n\nOptimisation\n\n\n \n\n\n\n\nSep 21, 2021\n\n\nDavid Linden, Marco Cinelli, Matteo Spada, admin , Patrick Gasser, Peter Burgherr\n\n\n\n\n\n\n\n\nA multidimensional high-resolution assessment approach to boost decentralised energy investments in Sub-Saharan Africa\n\n\nRenewable and Sustainable Energy Reviews\n\n\n\n\nIndicators\n\n\nEnergy\n\n\nPolicy\n\n\nSustainable development\n\n\n \n\n\n\n\nSep 1, 2021\n\n\nMagda Moner, Abbie Bender, William Becker, et al.\n\n\n\n\n\n\n\n\nA comprehensive comparison of total-order estimators for global sensitivity analysis\n\n\nInternational Journal for Uncertainty Quantification\n\n\n\n\nSensitivity analysis\n\n\nMonte Carlo\n\n\n \n\n\n\n\nJul 1, 2021\n\n\nArnald Puy, William Becker, Samuele Lo Piano, Andrea Saltelli\n\n\n\n\n\n\n\n\nVariable Selection in Regression Models Using Global Sensitivity Analysis\n\n\nJournal of Time Series Econometrics\n\n\n\n\nSensitivity analysis\n\n\nEconometrics\n\n\nModel selection\n\n\n \n\n\n\n\nMar 15, 2021\n\n\nWilliam Becker, Paulo Paruolo, Andrea Saltelli\n\n\n\n\n\n\n\n\nThe Future of Sensitivity Analysis: An essential discipline for systems modeling and policy support\n\n\nEnvironmental Modelling & Software\n\n\n\n\nSensitivity analysis\n\n\n \n\n\n\n\nMar 1, 2021\n\n\nSaman Razavi, Andrea Saltelli, Samuele Lo Piano, William Becker, Hoshin Gupta, Arnald Puy, Razi Sheikholeslami, et al.\n\n\n\n\n\n\n\n\nWrapping up the Europe 2020 strategy: A multidimensional indicator analysis\n\n\n\n\n\n\n\nIndicators\n\n\nPolicy\n\n\nSustainable development\n\n\n \n\n\n\n\nDec 1, 2020\n\n\nWilliam Becker, Hedvig Norlen, et al.\n\n\n\n\n\n\n\n\nMetafunctions for benchmarking in sensitivity analysis\n\n\nReliability Engineering & System Safety\n\n\n\n\nSensitivity analysis\n\n\nMachine learning\n\n\n \n\n\n\n\nDec 1, 2020\n\n\n\n\n\n\n\n\nDevelopment of a bioeconomy monitoring framework for the European Union: An integrative and collaborative approach\n\n\nNew Biotechnology\n\n\n\n\nIndicators\n\n\nPolicy\n\n\nSustainable development\n\n\n \n\n\n\n\nNov 25, 2020\n\n\nNicolas Robert, et al., William Becker\n\n\n\n\n\n\n\n\nThe Use of Quantitative Methods in the Policy Cycle\n\n\nScience for Policy Handbook\n\n\n\n\nSensitivity analysis\n\n\nPolicy\n\n\n \n\n\n\n\nJan 1, 2020\n\n\nGiuseppe Munda, Daniel Albrecht, William , Et al., Paolo Paruolo, Michaea Saisana\n\n\n\n\n\n\n\n\nWhy so many published sensitivity analyses are false: A systematic review of sensitivity analysis practices\n\n\nEnvironmental Modelling & Software\n\n\n\n\nSensitivity analysis\n\n\n \n\n\n\n\nApr 1, 2019\n\n\nAndrea Saltelli, William Becker, et al.\n\n\n\n\n\n\n\n\nGlobal sensitivity analysis for high-dimensional problems: How to objectively group factors and measure robustness and convergence while reducing computational cost\n\n\nEnvironmental Modelling & Software\n\n\n\n\nSensitivity analysis\n\n\nWater\n\n\n \n\n\n\n\nJan 1, 2019\n\n\nRazi Sheikholeslami, Saman Razavi, Hoshin Gupta, William Becker, Amin Haghnegahdar\n\n\n\n\n\n\n\n\nThe Water Retention Index: Using land use planning to manage water resources in Europe\n\n\nSustainable Development\n\n\n\n\nIndicators\n\n\nPolicy\n\n\nSustainable development\n\n\nWater\n\n\n \n\n\n\n\nApr 25, 2018\n\n\nIne Vandecasteele, William Becker, et al.\n\n\n\n\n\n\n\n\nSensitivity analysis approaches to high-dimensional screening problems at low sample size\n\n\nJournal of Statistical Computation and Simulation\n\n\n\n\nSensitivity analysis\n\n\nMonte Carlo\n\n\n \n\n\n\n\nApr 4, 2018\n\n\nWilliam Becker, Stefano Tarantola, Gregory Deman\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/2022_COINr/index.html",
    "href": "publications/2022_COINr/index.html",
    "title": "COINr: An R package for developing composite indicators",
    "section": "",
    "text": "About\nThe COINr package, introduced in this article, is an R package that aims to provide a harmonised development environment for composite indicators that includes all common operations from indicator selection, data treatment and imputation up to aggregation, presentation of results and sensitivity analysis. COINr enables development, visualisation and exploration of methodological variations, and encourages transparency and reproducibility.\n\nCOINr is hosted at its GitHub page here. All documentation is here."
  },
  {
    "objectID": "publications/2021_solarafrica/index.html",
    "href": "publications/2021_solarafrica/index.html",
    "title": "A multidimensional high-resolution assessment approach to boost decentralised energy investments in Sub-Saharan Africa",
    "section": "",
    "text": "About\nThere are over 650 million people in Africa who have no access to electricity; this is in sharp contrast to the continent’s vast untapped renewable energy potential and due largely to the historical lack of investments in energy infrastructure. New investments in decentralised power generation within Sub-Saharan Africa play a progressively important role in increasing energy access and addressing the continent’s electricity supply shortages. Tracking the performance of Sub-Saharan African countries along various socio-political and economic axes can spur the mobilisation of private, public and international sectors in investing in decentralised energy technologies. An increasing amount of high-resolution global spatial data are available, and used for various assessments. However, key multidimensional indicators are mainly still provided only at the national level. To this end, we present a comprehensive and consistent analysis of the attractiveness for decentralised photovoltaic technologies at an unprecedented level of detail using both high-resolution spatial data and national reports. We develop and build a new composite indicator that considers the interplay between social, political, environmental and financial factors at a granular regional level for Sub-Saharan Africa and embeds within it the importance of the local production costs at high-spatial resolution.\n\nSee interactive data exploration here. See also accompanying Data in Brief article."
  },
  {
    "objectID": "publications/2021_PCE/index.html",
    "href": "publications/2021_PCE/index.html",
    "title": "Polynomial chaos expansion for sensitivity analysis of model output with dependent inputs",
    "section": "",
    "text": "About\nIn this paper, we discuss the sensitivity analysis of model response when the uncertain model inputs are not independent of one other. In this case, two different kinds of sensitivity indices can be evaluated: (i) the sensitivity indices that account for the dependence/correlation of an input or group of inputs with the remainder and (ii) the sensitivity indices that do not account for this dependence. We argue that this distinction applies to any global sensitivity measure. In the present work, we focus on the estimation of variance-based sensitivity indices which are based on the second-order moment of the model response of interest. In particular, we derive new strategies and new computationally efficient methods to assess them, which rely on the polynomial chaos expansion. Several numerical exercises are carried out to demonstrate the performance of the new methods, including a sensitivity analysis of a drainage model posterior to its statistical calibration."
  },
  {
    "objectID": "publications/2021_FutureSA/index.html",
    "href": "publications/2021_FutureSA/index.html",
    "title": "The Future of Sensitivity Analysis: An essential discipline for systems modeling and policy support",
    "section": "",
    "text": "About\nSensitivity analysis (SA) is en route to becoming an integral part of mathematical modeling. The tremendous potential benefits of SA are, however, yet to be fully realized, both for advancing mechanistic and data-driven modeling of human and natural systems, and in support of decision making. In this perspective paper, a multidisciplinary group of researchers and practitioners revisit the current status of SA, and outline research challenges in regard to both theoretical frameworks and their applications to solve real-world problems. Six areas are discussed that warrant further attention, including (1) structuring and standardizing SA as a discipline, (2) realizing the untapped potential of SA for systems modeling, (3) addressing the computational burden of SA, (4) progressing SA in the context of machine learning, (5) clarifying the relationship and role of SA to uncertainty quantification, and (6) evolving the use of SA in support of decision making. An outlook for the future of SA is provided that underlines how SA must underpin a wide variety of activities to better serve science and society."
  },
  {
    "objectID": "publications/2020_QuantPolicy/index.html",
    "href": "publications/2020_QuantPolicy/index.html",
    "title": "The Use of Quantitative Methods in the Policy Cycle",
    "section": "",
    "text": "About\nThis Chapter presents a set of quantitative modelling approaches, connected to various steps of the policy cycle, that aim at helping policy-makers and all social actors involved, by providing a scientific sound framework for a systematic, coherent and transparent analysis. Practical guidelines for structuring policy problems by using uncertainty and sensitivity analysis, multi-criteria decision analysis, composite indicators and ex-post impact evaluation are provided.\n\nSee the entire Science for Policy Handbook here."
  },
  {
    "objectID": "publications/2020_EU2020/index.html",
    "href": "publications/2020_EU2020/index.html",
    "title": "Wrapping up the Europe 2020 strategy: A multidimensional indicator analysis",
    "section": "",
    "text": "About\nThe Europe 2020 Strategy was launched by the European Commission in 2010 to promote smart, sustainable, and inclusive growth across EU member states. As the strategy draws to a close in 2020 and is superseded by the Sustainable Development Goals and the Green Deal, this work aims to assess the progress made over the last decade, and to carry forward lessons for future endeavours. A composite indicator approach is adopted, which aggregates the distance of each country or region to politically-agreed targets. This allows a high-level summary of progress, but also examines detailed trends at national and regional levels, as well as by degree of urbanisation and by development. The results show that although the EU has moved forward as whole, some regions have lagged behind or even moved backwards, and within some countries, regions are moving further away from one another. Progress has been particularly strong in education, but more work is needed in the environmental dimensions."
  },
  {
    "objectID": "publications/2019_WhySAFalse/index.html",
    "href": "publications/2019_WhySAFalse/index.html",
    "title": "Why so many published sensitivity analyses are false: A systematic review of sensitivity analysis practices",
    "section": "",
    "text": "About\nSensitivity analysis provides information on the relative importance of model input parameters and assumptions. It is distinct from uncertainty analysis, which addresses the question ‘How uncertain is the prediction?’ Uncertainty analysis needs to map what a model does when selected input assumptions and parameters are left free to vary over their range of existence, and this is equally true of a sensitivity analysis. Despite this, many uncertainty and sensitivity analyses still explore the input space moving along one-dimensional corridors leaving space of the input factors mostly unexplored. Our extensive systematic literature review shows that many highly cited papers (42% in the present analysis) fail the elementary requirement to properly explore the space of the input factors. The results, while discipline-dependent, point to a worrying lack of standards and recognized good practices. We end by exploring possible reasons for this problem, and suggest some guidelines for proper use of the methods."
  },
  {
    "objectID": "publications/2018_WaterRetention/index.html",
    "href": "publications/2018_WaterRetention/index.html",
    "title": "The Water Retention Index: Using land use planning to manage water resources in Europe",
    "section": "",
    "text": "About\nAppropriate land management can be an effective approach to improving water quantity regulation. There is, however, a need to identify both where measures are most needed and where they may be most effective. The water retention index (WRI) was developed with this goal in mind. The WRI is a composite indicator which takes into account parameters reflecting potential water retention in vegetation, water bodies, soil and underlying aquifers, as well as the influence of slope and artificially sealed areas. Three land management scenarios were simulated up to 2030 using the LUISA modeling platform: increasing grassland in upstream areas as well as afforestation in both upstream areas and riparian zones. The WRI was computed for all scenarios as well as a comparative “business-as-usual” baseline scenario. All scenarios showed an overall improvement of the index as compared to this baseline, with afforestation in upstream areas having the greatest effect. The WRI can provide useful insights into the current capacity of a landscape to regulate water as well as the effectiveness of possible remediation strategies applied at the European scale."
  },
  {
    "objectID": "projects/WEF/index.html",
    "href": "projects/WEF/index.html",
    "title": "Water-Energy-Food Nexus Index",
    "section": "",
    "text": "The WEF (Water-Energy-Food) framework consists of a series of indicators used since 2011 to assess availability and access to resources, and their sustainable development at a global level.\nI was contracted to do the main model calculation of the WEF Nexus Index, including global sensitivity analysis and providing expert advice."
  },
  {
    "objectID": "projects/UNIDO/index.html",
    "href": "projects/UNIDO/index.html",
    "title": "Quality Infrastructure for Sustainable Development Index",
    "section": "",
    "text": "Quality infrastructure (QI) includes standards, conformity assessment, accreditation and metrology, and is the foundation for international trade. QI promotes sustainable development, through promoting economic development and raising health and environmental standards, among other things.\nOver 2020-2022 I led the development of the Quality Infrastructure for Sustainable Development Index for the United Nations Industrial Development Organisation, which aims to measure at the national level, how each country’s QI is suitable for reaching sustainable development goals. This process involved:\n\nClient engagement\nLiterature review\nStakeholder engagement, expert workshops\nData collection (including web scraping), cleaning\nData analysis and processing, modelling\nPresentation, visualisation\nReporting and extracting policy messages\nObtaining feedback and making adjustments\nWorking with other consultants and professionals to deliver the best outcome"
  },
  {
    "objectID": "projects/Programme monitoring/index.html",
    "href": "projects/Programme monitoring/index.html",
    "title": "European programme monitoring",
    "section": "",
    "text": "I worked with the European Commission’s Directorate-General for Budget in analysing performance data for all European budget programmes, covering many billions of EUR, with the aim of providing a harmonised reporting framework.\nI also helped to develop guidelines for programme monitoring, for the present multi-annual financial framework, and advised in meetings with the Regulatory Scrutiny Board.\nThis was multi-year support work which involved data analysis and client engagement, as well as regularly attending meetings in Brussels and presenting work."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "European Skills Index\n\n\nUpdating and improving the European Skills Index for Cedefop.\n\n\n\nSkills\n\n\nPolicy\n\n\nIndicators\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEDGAR: Global emissions database\n\n\nEDGAR is a highly detailed global database of greenhouse gas and pollution emissions maintained by the European Commission.\n\n\n\nSustainabilty\n\n\nClimate\n\n\nPolicy\n\n\n\n\nJan 9, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA2SIT app for community-based protection\n\n\nMeasuring migrant and refugee vulnerability in Guatemala.\n\n\n\nIndicators\n\n\nSustainable development\n\n\nPolicy\n\n\n\n\nJan 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraining\n\n\nTraining courses, lecturing and tuition.\n\n\n\nOther\n\n\n\n\nJan 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVietnam provincial innovation index\n\n\nAuditing and assisting with an index to measure innovation at the regional level in Vietnam.\n\n\n\nInnovation\n\n\nPolicy\n\n\nIndicators\n\n\n\n\nJan 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComposer App\n\n\nA web app for building and analysing composite indicators\n\n\n\nSoftware\n\n\nIndicators\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCOINr: An R package for composite indicators\n\n\nMy R package is used worldwide by professional developers.\n\n\n\nSoftware\n\n\nIndicators\n\n\n\n\nSep 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEU Bioeconomy Indicators\n\n\nTime series analysis for bioeconomy indicators.\n\n\n\nIndicators\n\n\nSustainable development\n\n\n\n\nAug 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal Innovation Index\n\n\nCustom R package development for innovation modelling\n\n\n\nIndicators\n\n\nInnovation\n\n\nSoftware\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWater-Energy-Food Nexus Index\n\n\nModel calculation and global sensitivity analysis.\n\n\n\nIndicators\n\n\nSustainable development\n\n\n\n\nMar 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuality Infrastructure for Sustainable Development Index\n\n\nLinking quality infrastructure and sustainable development with a data-driven analysis.\n\n\n\nIndicators\n\n\nSustainable development\n\n\nPolicy\n\n\n\n\nDec 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOther projects\n\n\nAn overview of other projects.\n\n\n\nOther\n\n\n\n\nFeb 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCOIN Tool\n\n\nAn advanced Excel tool for composite indicators\n\n\n\nSoftware\n\n\nIndicators\n\n\n\n\nNov 4, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEuropean programme monitoring\n\n\nMonitoring European spending programmes.\n\n\n\nPolicy\n\n\n\n\nJun 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImpact assessment\n\n\nEx-ante impact assessments for European policy making.\n\n\n\nPolicy\n\n\n\n\nJan 1, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAsia-Europe Connectivity\n\n\nMeasuring sustainable connectivity between Europe and Asia\n\n\n\nIndicators\n\n\nSustainable development\n\n\nPolicy\n\n\n\n\nOct 20, 2018\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/GII/index.html",
    "href": "projects/GII/index.html",
    "title": "Global Innovation Index",
    "section": "",
    "text": "Over 2021-2022 I have developed a custom R package for the UN’s World Intellectual Property Organisation. This involved building a streamlined package capable of building the Global Innovation Index (a hierarchical composite indicator), including data screening, data treatment, normalisation and aggregation.\nThe package also allows ex-post checks on methodological assumptions, and automatically yields data for generating country profiles. This greatly saves time and dramatically reduces the possibility of errors in the complex model evaluation.\nThe package is hosted at a private repo on Github."
  },
  {
    "objectID": "projects/EDGAR/index.html",
    "href": "projects/EDGAR/index.html",
    "title": "EDGAR: Global emissions database",
    "section": "",
    "text": "EDGAR is “a multipurpose, independent, global database of anthropogenic emissions of greenhouse gases and air pollution on Earth”.\nAlthough most countries provide estimates of their greenhouse gas emissions, the timeliness and accuracy of these estimates may not always be sufficient. EDGAR provides completely independent and highly detailed estimates of emissions using activity data, which is particularly crucial in countries who may not have the capacity to accurately report emissions.\nMy work at the European Commission’s Joint Research Centre is to help with the EDGAR database, in particular to implement a tool for calculating uncertainty on emissions estimates following IPCC guidelines that interacts automatically with the database. I will also be involved in data collection and F-gases.\nThis is a new project started in 2023 so I am still getting familiar with the database, but so far it has been fascinating to learn how emissions are calculated and I am looking forward to getting deeper into the project."
  },
  {
    "objectID": "projects/COINrApp/index.html",
    "href": "projects/COINrApp/index.html",
    "title": "Composer App",
    "section": "",
    "text": "The open-source COINr package is now used worldwide for building and analysing composite indicators. However, for those people who don’t use R, it is hard to access.\nThe Foundation for Innovative New Diagnostics (FIND) is a non-profit organisation which “seeks to ensure equitable access to reliable (medical) diagnosis around the world. Early in 2023 I began working with them to develop a Shiny app which can build composite indicators to help them identify in which countries to direct their resources.\nThe app is essentially a front end for the COINr package, but also has a number of modifications and tries to strike a balance between flexibility and not overwhelming the user with too many options. Its features include:\n\nUpload of any data set and index structure\nScreening units by data availability\nImputation of missing data\nOutlier treatment\nNormalisation and aggregation\nStats, maps, bar and bubble charts\nUnit profiles\nGlobal sensitivity analysis and reweighting\n\nI leave a couple of screenshots here, and hopefully the app will be made freely available in the near future!"
  },
  {
    "objectID": "projects/Bioeconomy/index.html",
    "href": "projects/Bioeconomy/index.html",
    "title": "EU Bioeconomy Indicators",
    "section": "",
    "text": "I was contracted by the European Commission’s Joint Research Centre to provide a time series analysis of the EU Bioeconomy indicators data set. The analysis covered data from 1990-2022. Custom code was written and added to my COINr package, and a full analysis provided.\nI created a data pipeline which automatically analyses data after updates, and provides results tables to generate indicator dashboards. More info about the bioeconomy monitoring system here."
  },
  {
    "objectID": "projects/A2SIT/index.html",
    "href": "projects/A2SIT/index.html",
    "title": "A2SIT app for community-based protection",
    "section": "",
    "text": "The United Nations High Commissioner for Refugees (UNHCR) is a UN agency that helps to protect the rights and wellbeing of people who have been forced to flee from their homes. In Guatemala, there are many such refugees and forcibly displaced people, typically moving from southern countries (such as Honduras, El Salvador) northwards. One of the activities of the UNHCR in Guatemala is to provide community-based protection (CBP) for these people, however due to the complexity of the situation more information is need to understand where CBP should be directed.\nMy work for the UNHCR is to build a web app to measure the vulnerability of populations at the municipal level in Guatemala by bringing together indicators measuring threats, socioeconomic circumstances, and response capacities to give a summary measure which helps to identify the municipalities that are in most need of CBP.\nThe resulting app, which is called the Admin-2 Severity Index Tool (A2SIT) is a fairly complex Shiny app which runs on an R server. It is encapsulated in an R package that I also built called A2SIT which is available on GitHub. I should mention that although I built the app and package, a huge amount of work was done in collecting the data, helping guide the app and designing the index, as well as many other things during the project.\nIn the app you can:\n\nUpload your own data set which should be at the Admin 2 level for one of the supported countries\nObtain a statistical analysis of your data and flagged issues for indicators\nCalculate index results and plot them on a map, and as tables and bar charts\nPlay with composite indicator settings\nView and compare profiles of municipalities\nCompare scenarios\n\nThere is also fairly comprehensive documentation which is available in an online book!\nThis has been a big project and I have learned a lot. But it has also been very rewarding. The app has been successful in testing with users, and should be rolled out to other countries in Central and South America. There is also a Medium article on the app.\n\n\n\nData analysis\n\n\n\n\n\nMapping and results\n\n\n\n\n\nRegion profiles"
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html",
    "href": "posts/2023-12-21_Wrapup2023/index.html",
    "title": "2023 Wrap Up",
    "section": "",
    "text": "So it’s the end of 2023, I’ve closed all the big projects that needed closing before Christmas, and thought that a little summary of the year was in order.\n2023 was a very busy but also very interesting year for me. As usual in freelance mode, things go up and down quite a lot: the start of the year was fairly manageable, June and July were crazy-busy, the summer was a nice break but I paid for that dearly in September until the end of November period in which a lot of big projects needed finishing at the same time and I nearly melted! Now at the end of December I’m feeling pretty relaxed and everything is fine. Which is why I finally have some time to write something here.\nSo, looking back on the year, here is how it went."
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#ghg-emissions-analysis",
    "href": "posts/2023-12-21_Wrapup2023/index.html#ghg-emissions-analysis",
    "title": "2023 Wrap Up",
    "section": "GHG Emissions Analysis",
    "text": "GHG Emissions Analysis\nThings kicked off in early January when I started working half-time as a data scientist at the European Commission’s Joint Research Centre (JRC), in the EDGAR group which produces and manages a global database on greenhouse gas (GHG) emissions. Although I’d previously worked in the JRC for quite a few years, this was a completely new topic and it took me a while to find my feet and learn all about different GHG emissions, how they are estimated, and the technical ins and outs of the database. After this burn-in period however, and some sharpening my SQL skills, I managed to produce a custom R package and app which allows uncertainty estimation of GHG emissions across any sector, country, substance and time point. Here’s a little snapshot of the uncertainty estimations:\n\n\n\nTotal GHG emissions for top emitters\n\n\nIt looks quite straightforward but a lot of work went into it!\nAnyway my JRC EDGAR work has been the stable half of my work for the whole of 2023 and I’m glad to say I will be continuing with the group well into 2024."
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#community-based-protection-tool-for-unhcr",
    "href": "posts/2023-12-21_Wrapup2023/index.html#community-based-protection-tool-for-unhcr",
    "title": "2023 Wrap Up",
    "section": "Community-based protection tool for UNHCR",
    "text": "Community-based protection tool for UNHCR\nAnother big project that has run through 2023 is building the A2SIT app for UNHCR Guatemala. This started in January when I was contracted to begin work building the back-end code to build a composite indicator to understand which municipalities were most in need of community-based protection in Guatemala. The UNHCR team were in the process of collecting indicators and data, and I helped them build the composite indicator and the data pipeline to calculate index scores, using as usual the COINr package. At the end of the initial contract, I also floated the idea that I could build the front end of the app using Shiny, and this led to more work with them, and now I’m very proud to say the A2SIT app is deployed and has been presented to UNHCR offices in various countries as a general tool for measuring “severity”. I’m just wrapping up what will probably be my last contributions to the project as it is pretty much finished, but to give some highlights:\n\nThe app is built in Shiny using Shinydashboardplus\nIt takes a custom set of indicators and data uploaded in an Excel file\nIt builds a composite indicator of severity, returning results and statistics\nResults are plotted on interactive maps\nProfiles are generated for all regions\nUsers can upload their own shape files to build composite indicators for any set of regions or countries\nThe app is fully documented in an online book\n\n\n\n\nScreenshot of A2SIt app\n\n\nRead some more about the A2SIT app and project in a Medium article here."
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#a-composite-indicator-app",
    "href": "posts/2023-12-21_Wrapup2023/index.html#a-composite-indicator-app",
    "title": "2023 Wrap Up",
    "section": "A Composite Indicator App",
    "text": "A Composite Indicator App\nEarly in 2023 I began working with the Foundation for Innovative New Diagnostics (FIND) to build an app which can build composite indicators for any set of indicators and countries/regions/units. After much hard work through 2023 with a number of talented people, we have deployed a Shiny app which is being trialled within FIND to help prioritise resources to promote medical diagnosis in developing countries. The app should soon also be released as an open-source R package.\n\n\n\nScreenshot of “Composer” app\n\n\nThe app (working name “Composer”) is effectively an accessible front end for the COINr package, including options for imputation of missing data, outlier treatment, normalisation, aggregation and global sensitivity analysis, not to mention various visualisations in maps, bar and bubble charts. Hopefully some more news on the open source version soon!"
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#quality-infrastructure-for-sustainable-development",
    "href": "posts/2023-12-21_Wrapup2023/index.html#quality-infrastructure-for-sustainable-development",
    "title": "2023 Wrap Up",
    "section": "Quality Infrastructure for Sustainable Development",
    "text": "Quality Infrastructure for Sustainable Development\nContinuing my work with the United Nations Industrial Development Organisation (UNIDO), I began working on the update to the Quality Infrastructure for Sustainable Development (QI4SD) Index which I helped to create in 2020. The index, which has attracted some interest around the world and has been adopted by a number of countries as a national performance indicator, should have a full update in 2024.\nTo bring in as much expert feedback as possible for the update of the index, I worked with UNIDO colleagues to organise two expert workshops: one in Riyadh, Saudia Arabia; and the other in Vienna; in which we presented in detail the index methodology and discussed ways in which it can be improved.\nThe QI4SD Index should be released again in late 2024."
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#global-innovation-index",
    "href": "posts/2023-12-21_Wrapup2023/index.html#global-innovation-index",
    "title": "2023 Wrap Up",
    "section": "Global Innovation Index",
    "text": "Global Innovation Index\nIn 2023 I continued an excellent collaboration with colleagues and friends in the World Intellectual Property Organisation (WIPO) working on the Global Innovation Index (GII). As part of an innovative team, I have helped redesign the back end of the GII, wrapping the modelling in a custom R package and contributing to documentation, data collection and auditing.\nI’m always pround to be part of the GII, which remains one of the highest-quality composite indicators that I have been involved with (and I have worked on many!), from the data collection, processing and auditing, up to the exploration and messaging of the results."
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#european-skills-metrics",
    "href": "posts/2023-12-21_Wrapup2023/index.html#european-skills-metrics",
    "title": "2023 Wrap Up",
    "section": "European Skills Metrics",
    "text": "European Skills Metrics\nI was proud to be part of a winning consortium in a bid to update and maintain the European Skills Index (ESI) for Cedefop, a European agency which supports development of European vocational education and training policies and contributes to their implementation.\nWorking with the Fondazione Brodolini, an Italian consultancy, we have moved the calculation of the ESI to a fully-reproducible programmatic back end based around the COINr package. All data has now been collected and we expect to release the updated results in early 2024."
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#other-things",
    "href": "posts/2023-12-21_Wrapup2023/index.html#other-things",
    "title": "2023 Wrap Up",
    "section": "Other things",
    "text": "Other things\nEven more things I worked on this year!\n\nI was commissioned to write a study by the European Commission on the prevalence of sensitivity analysis in impact assessments\nI ran the back-end modelling for the Water-Energy-Food Nexus Index, as I have done annually since 2019\nI audited the Vietnam Provincial Innovation Index, and was very pleased to meet the talented staff behind its creation near my home in Ispra, Italy!\nI made many further updates to the COINr package to which I have now made over 900 commits\n\nFinally I’m pleased to say that I have become an associate consultant at Technopolis Group, a consultancy that works extensively in European policy in Brussels (and also with many offices worldwide). Very happy to be on board and to be working on projects in the new future!"
  },
  {
    "objectID": "posts/2023-12-21_Wrapup2023/index.html#and-so",
    "href": "posts/2023-12-21_Wrapup2023/index.html#and-so",
    "title": "2023 Wrap Up",
    "section": "And so…",
    "text": "And so…\nAnd so. This has been a really busy but very rewarding year. Although I have been through some very busy periods I’ve had my time off and overall I think it has balanced out quite nicely.\nI’m extremely happy to have worked on so many interesting projects, with so many inspiring people. Here’s to another good year in 2024!"
  },
  {
    "objectID": "posts/2023-11-20_WEF_update/index.html",
    "href": "posts/2023-11-20_WEF_update/index.html",
    "title": "Updates of the WEF Nexus Index",
    "section": "",
    "text": "The WEF Nexus Index is a composite indicator which measures integrated resource management and sustainable development across the three sectors of Water, Energy and Food.\nI have been involved in this index for several years and it has been an interesting project getting a glimpse into the the world of resource management. Recently I was responsible for calculation of the latest results, so that the next version can be launched soon.\nSneak peek of who is top of the rankings….? In first place, still, is Iceland! Not really surprising given it has a lot of resources in terms of water, geothermal energy and so on."
  },
  {
    "objectID": "posts/2023-11-10_Vienna_workshop/index.html",
    "href": "posts/2023-11-10_Vienna_workshop/index.html",
    "title": "Expert group meeting on quality infrastructure in Vienna",
    "section": "",
    "text": "Hot on the heels of the Riyadh workshop on Quality Infrastructure (QI), I attended the Expert Group Meeting (EGM) for the QI4SD Index, hosted at UNIDO headquarters in Vienna, Austria.\nThe objective of the workshop was to present the methodology of the QI4SD Index in detail to a group of around 40 experts from QI organisations including ISO, IEC, BIPM, OIML and many representatives from national standards bodies and other QI-related institutions, in order to receive feedback to improve the index in its next update.\nThe QI4SD Index is an index for measuring quality infrastructure and its contributions to SDGs, which I helped to build starting in 2020. It was launched in 2022, and has since gained quite some visibility and has been adopted by some countries as a national KPI for measuring progress. Subsequently, UNIDO would like to launch and updated version of the index in 2024. The workshop therefore feeds directly into improving the index.\nThe outcomes of the workshop were many pages of excellent feedback which we are now digesting. As usual in these workshops, some suggestions are more feasible than others, and we can only do so much in the update next year, but all feedback was extremely welcome.\nWe should begin working on the index update early in 2024."
  },
  {
    "objectID": "posts/2023-09-28_COIN_training/index.html",
    "href": "posts/2023-09-28_COIN_training/index.html",
    "title": "COIN training on composite indicators",
    "section": "",
    "text": "So on the 28th of September I gave a couple of invited talks at the 2023 JRC Week on Composite Indicators and Scoreboards, whic is spread over a few days and delves into all the technical and non-technical intricacies of building and analysing composite indicators.\nI have helped with this training course for some years, particularly when I worked full time in the JRC’s Competence Centre for Composite Indicators and Scoreboards. In this case I gave two lectures:\n\nQuality control and robustness, in which I explain the main concepts for testing robustness (sensitivity analysis) and give some tips for building high-quality composite indicators.\nA lecture on building and auditing composite indicators with R\n\nFor the first lecture you can find the slides here, and the video you can find here (the lecture starts about 14:35).\nIn the second lecture I built a code demo which is available as an HTML page on GitHub here. In this notebook, I show how to:\n\nDownload data from the Eurostat API in R\nPass the data and structure into COINr\nAnalyse the data and calculate the results\nMap the data interactively using Leaflet\nExplore some methodological variations\nExport everything to Excel\n\nThis encapsulates many of the points that I think go in to making a good composite indicator. If you want to hear more about it, check out the recording and skip to approximately 16:28. Unfortunately there were a few technical problems throughout the lecture so you may need to skip ahead on occasions!"
  },
  {
    "objectID": "posts/2023-07-28_A2SIT_launch/index.html",
    "href": "posts/2023-07-28_A2SIT_launch/index.html",
    "title": "A2SIT App launched for UNHCR",
    "section": "",
    "text": "’ve just come to the end of a very interesting contract working for the UNHCR in Guatemala (for the moment).\nAs you might know, the UNHCR helps displaced people around the world and protects human rights. In many places in the world there are movements of forcibly diplaced people, including refugees. Guatemala is one place where people are usually moving from South to North seeking refuge, asylum or simply a better life.\nOne issue faced by UNHCR staff is understanding where in the country to direct their limited resources to help people. There are many factors that can be used to decide where to intervene, and the picture can rapidly become complex.\nTo help this situation, I was contracted by UNHCR to build an app which can be used to construct composite indicators of “severity” at the municipal level (called “Admin-2” level by the UNHCR classification) in Guatemala.\nThe app, which is called the Admin-2 Severity Index Tool (A2SIT) is a fairly complex Shiny app which runs on an R server. It is encapsulated in an R package that I also built called A2SIT which is available on GitHub. I should mention that although I built the app and package, a huge amount of work was done in collecting the data, helping guide the app and designing the index, as well as many other things during the project.\nIn the app you can:\n\nUpload your own data set which should be at the Admin 2 level for one of the supported countries\nObtain a statistical analysis of your data and flagged issues for indicators\nCalculate index results and plot them on a map, and as tables and bar charts\nPlay with composite indicator settings\nView and compare profiles of municipalities\nCompare scenarios\n\nThere is also fairly comprehensive documentation which is available in an online book!\nThis has been a big project and I have learned a lot. But it has also been very rewarding. The app has been successful in testing with users, and should be rolled out to other countries in Central and South America. There is also a Medium article on the app.\n\n\n\nData analysis\n\n\n\n\n\nMapping and results\n\n\n\n\n\nRegion profiles"
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html",
    "href": "posts/2022-12-16_Freelancing/index.html",
    "title": "Freelance data science: a two-year review",
    "section": "",
    "text": "I started working as a freelancer back in October 2020. Since then I’ve worked on all kinds of projects and it’s been a real journey: sometimes hectic, sometimes slow, but always unpredictable. After more than two years, I thought a long and rambling review was in order, so here it is!"
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html#a-new-era-sunrise",
    "href": "posts/2022-12-16_Freelancing/index.html#a-new-era-sunrise",
    "title": "Freelance data science: a two-year review",
    "section": "A New Era :sunrise:",
    "text": "A New Era :sunrise:\nUp until March 2020 I worked at the European Commission’s Joint Research Centre (JRC). I worked there for nine years, and it was a really fantastic experience supporting European policy making, doing research, meeting and working with great people, and living in a rather nice corner of Italy near the mountains and the lakes. Unfortunately, while the JRC is great for temporary contracts, permanent contracts are much harder to come by. And by early 2020 my time was up, and as a Brexit refugee I was also excluded from applying to the Commission at all. Thanks Boris. :clown:\nMarch 2020 also coincided with the start of the pandemic and a long lockdown in Italy, so my first months outside the JRC were not the honeymoon of casual family time, projects and sports that I had envisaged. Anyway, for various reasons it was clear that we (me and my family) would stay in the area for a while yet. And so after a few months I began looking for work options.\nThe problem is that living in a small town in a mostly rural area in North Italy, on-site work options in my line of work basically consist of:\n\nThe JRC\nSee 11\n\nAnd so, this was how I found myself looking at freelance work. One of the few positive outcomes of the pandemic was that remote work became much more normalised, and so this was more feasible than previously. And so I began my journey as a self-styled “freelance data scientist”."
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html#the-journey-tent",
    "href": "posts/2022-12-16_Freelancing/index.html#the-journey-tent",
    "title": "Freelance data science: a two-year review",
    "section": "The Journey :tent:",
    "text": "The Journey :tent:\nIt really has been a Journey. Coming out of the JRC I realised I had a mixed bag of skills and experience: technical skills in statistics, indicators, modelling and sensitivity analysis; but also a lot of experience in various areas of policy - in sustainable development, connectivity, budgeting, and countless other areas that I had worked in. I had also written a lot of academic papers, organised and participated in numerous scientific conferences, and somehow built up a fairly wide network of friends and colleagues that I had worked with over the years.\nSo, if I was to become a freelancer, what kind of work should I actually do?\nLuckily, work came my way and answered this question for me. I was first contracted by the JRC to build an R package for composite indicators, which turned into the rather successful COINr package. During this time I also began working with WIPO to build a similar custom R package for the Global Innovation Index, and with UNIDO to help build the Quality Infrastructure for Sustainable Development Index.\nI learned an enormous amount during these three projects. Whereas programming had been an occasional past-time in my time at the JRC, now it became my main work. I had to quickly improve my programming skills to a more professional level - learning about GitHub, version control, functional and object-oriented programming, unit testing, continuous integration and other concepts that I had little knowledge of before.\nAlong the way I also worked on some smaller projects, including the WEF Nexus Index. There I met the data visualisation experts at OneTandem, with whom I also began to work on other projects. Together with another colleague Hedvig Norlén, we launched the compositeindicators.com website where we offer services related to composite indicator construction.\nIn the end, 2021 got a bit too busy so I decided to take a break in early 2022, and I had a relatively quiet period up until early Summer when things started heating up again. And now, at the end of 2022 I have loads of work in the pipeline and I’m busy. So busy in fact, that I am procrastinating by writing a long blog post about the last two years!\nBut apart from all the professional skills that I have learned, I also really learned a lot about freelancing in general. And that’s why I thought I’d talk about some pros and cons. So here they are."
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html#the-good",
    "href": "posts/2022-12-16_Freelancing/index.html#the-good",
    "title": "Freelance data science: a two-year review",
    "section": "The Good",
    "text": "The Good\nI get to work on all kinds of topics :rainbow:\nProbably the best thing about my work is the variety. I have been lucky to work on so many topics, and with so many interesting people, over the last two years. Here are some topics that I’ve worked as a freelancer, or am about to begin working on:\n\nInnovation\nQuality infrastruture\nSustainable development\nBioeconomy\nMedical diagnosis\nWater/Energy/Food\nInternational connectivity\nMigration\nAir pollution\nEmployee skills\nImpact assessment\nSensitivity analysis\n\nThat’s quite a good list! Every time I start on a new project I’m fascinated to learn about the new topic. Ok, some topics are more interesting than others, but to me it’s a great privilege to be able to work in all these different fields. It’s the great thing about stats and data science, it can really be applied to almost anything! And my “clients” are spread over five continents at the last count.\nI am Il Capo of my time :hourglass:\nWorking freelance is extremely flexible. I can work to my own timetable, I can take days off without asking anyone. I can get up and work in the middle of the night if I want to (I don’t, but maybe that option will come in handy one day…?). This does also come with downsides (see later) but the good part is that, as long as I get the job done for my clients, and work the time I am paid to work, I can completely manage my own time. For example, in quieter periods I have sometimes just worked mornings and spent the afternoons doing other things like sport, house and family tasks, music etc. I can also work from anywhere, in any country.\nI am El Jefe of my work :tophat:\nAnother great thing is that I get to decide which work to do, and I can use whatever tools I like to get the job done (as long as my clients agree). Working in the European Commission, you are restricted to using a lot of corporate tools and you may have to ask to install new software, and so on. Now, I do all my work on open-source software, I have everything saved on the cloud so I can access all of my work, even on my phone. Also, if I don’t like a project, I can turn it down.\nThere’s less admin :page_facing_up:\nOk this is not completely true (see later) but some admin-related tasks disappear. I don’t have to produce briefings and I don’t have to attend many meetings. Of the meetings I do attend, they are usually short and well-focused. I don’t have to have performance review conversations, and I manage all my own IT, billing, leave and other things. I recall many difficult interactions with the more bureaucratic arms of the EC, although it’s just a fact of working in a very big organisation. Still, I don’t miss that part at all!"
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html#the-bad",
    "href": "posts/2022-12-16_Freelancing/index.html#the-bad",
    "title": "Freelance data science: a two-year review",
    "section": "The Bad",
    "text": "The Bad\nOk, now let’s see the other side of the coin!\nI’m a Lone Wolf :wolf:\nAlthough I work for many people, and I have even worked with some great colleagues, there’s no denying that freelancing is a bit of a lonely business. I work completely remotely, which is also a good thing, but it means that most days I work on my own. Of course, I have my family around, and I have meetings every now and then with clients, but I’m a social animal (half of the time) and I do miss being part of a team, working together with colleagues and friends in person and having coffee breaks and lunches together.\nWhen you work in an organisation and in a team there is also a feeling of being “part of something”, that you miss as a freelancer. I’m a mercenary, a hired gun - I do the work I’m paid to do and then when it’s done, I move onto something else. This is also a good thing, but I guess like the classic wandering cowboys, you do miss the feel of having a home! Oh yes this is getting poetic!\nWorkload goes up and down :roller_coaster:\nLike any job, freelancing workload goes through quiet and busy periods. The difference is that if you work for an employer (i.e. a “normal job”) you are paid the same regardless. You have a fixed salary per month, and it is the employer’s responsibility to ensure that your workload is not too much or too little.\nAs a freelancer, if you have less work, you have less money. So if you go through a quiet period you have to spend time looking for work. At the other end of the spectrum, it is easy to overload yourself with too many contracts and end up having to work during the evenings as well. It’s very difficult to get exactly the right amount of work, with contracts overlapping, starting and stopping, and meeting deadlines on various projects. This is something that gets easier with experience but is still a challenge.\nNo work, no pay :gun:\nIf I’m not working on a paid project then I’m not earning money. This is obvious but comes with some implications. First, if you are sick, you don’t get paid. Luckily I’m not often sick, but if I were to be sick for a long period of time, I would have no income. There’s no safety net.\nSecond is that you can’t easily do unpaid but interesting activities that you might have done as an employee. For example, when I was working at the JRC I could spend some time on academic research, and I went to many conferences. I also frequently gave talks at seminars, lectures at universities and so on. This was possible because I could do it during my working time, and the JRC would pay for me to travel to conferences (within reason). As a freelancer, I have also been invited to give talks at workshops and to collaborate on papers but usually I have to turn these down. If I spend the morning giving a talk, or working on a paper, I have to give up half a day’s pay. This is OK sometimes but hard to justify in many cases. And so, I end up focusing mostly on paid work.\nAnd finally of course, if I don’t find contracts, I don’t get paid. This means that there is very little job security. True, so far I have not had trouble finding work, but who knows for the future?\nThere’s more admin :page_facing_up:\nDid I say there was less admin? Well, actually I’m not sure. There are a lot of admin things to do as a freelancer. You have to draw up contracts and proposals for contracts, bill clients, talk to accountants, deduct expenses, and carefully monitor your time on each project, tracking the progress of deliverables and making sure you complete the work in the required time. There is also a lot of deliberation about how to define deliverables, whether to charge by deliverables or by time, estimating costs and so on. Actually it all adds up rather quickly.\nToo much flexibilty? :worried:\nFlexibility is great, but the price is that work and home life can blur so much that you find yourself in a permanent limbo between an “on” and “off” state. This is compounded by the fact that I work at home. When I began freelancing, I often worked in the evenings to “get a bit extra done”, knowing that whenever I work, my time is paid. However, I learned after a while that you have to try to draw a line between your working day and your non-work time. Now, I work fairly rigidly 8am-5pm, but I still occasionally find myself working a little in the evenings, or else drifting to non-work tasks during the day. I guess it just requires a measure of time management and discipline."
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html#the-summary",
    "href": "posts/2022-12-16_Freelancing/index.html#the-summary",
    "title": "Freelance data science: a two-year review",
    "section": "The Summary",
    "text": "The Summary\nFreelancing has been great for me and a huge learning experience. I think the main good things are the variety, the flexibility, and the sense of being in charge of your own destiny. On the other hand, it is quite a solitary experience, you have to be quite disciplined with your time and it comes with little job security.\nApart from learning all kinds of professional skills, I also learned some overall lessons. First is that contacts are all-important. I’m not a networker in the sense of someone who sidles up to “important” people at conferences or cold-calls potential clients. But I am someone who is very open to working with anyone on any kind of project, as long as it is interesting. This attitude, I think, has paid off: when I left the JRC I had worked with many people in many places and this led to recommendations and work. The fact is that if you get the work done to a good standard, and you are an easy person to work with, over time this gets noticed and you don’t have to aggressively network to build up a good list of contacts.\nAnother thing I learned is that academic papers are not very important outside of academia. Probably not a surprise to anyone, but unless you are planning on working in academia, no one really cares about how many citations you have!\nI also learned that having a broad profile has its pros and cons. Whereas I tend to think of myself as a “jack of all trades”, quite frequently I think I come across (to people who don’t know me) as a rather a “master of none”. I think that’s due to the fact that I have always loved learning new things and working in new fields, but try putting this on a CV when applying for a job. Usually employers like for people to fit into neat categories, and if your CV is very mixed, its hard to make head or tail of it. I still think a broad profile is a strength, but communicating it as a strength is really a challenge.\nI’ll end this extremely long post with a last positive thought about freelancing. Working at the JRC, like any big organisation, can feel a bit like being in a bubble. This is well-known in the JRC, and its the result of bring a lot of sciency people together from different corners of Europe on temporary contracts - naturally they tend to socialise together and talk about JRC stuff, and it can be easy to not get so involved in the outside world. At least for the years that you are working there, the JRC offers a great level of job security and benefits. In short, the bubble is quite cozy.\nWhen I left the JRC, therefore, it was also a test of whether I could stand on my own feet in the cold world outside of the bubble. And I’m glad to say after two years that I can. I have managed to get regular and interesting work, and I could probably carry on doing this almost indefinitely. So, although I may at some point seek the job security and the company of friends and colleagues back in Commission or another big organisation, I do at least know that, if the bubble bursts, I’ll be absolutely fine!"
  },
  {
    "objectID": "posts/2022-12-16_Freelancing/index.html#footnotes",
    "href": "posts/2022-12-16_Freelancing/index.html#footnotes",
    "title": "Freelance data science: a two-year review",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nTo be fair, you could also travel to Milan every day, but… nah.↩︎"
  },
  {
    "objectID": "posts/2022-10-11_COINr_Paper/index.html",
    "href": "posts/2022-10-11_COINr_Paper/index.html",
    "title": "Paper for COINr published",
    "section": "",
    "text": "Yesterday I was very pleased to have my paper, entitled “COINr: An R package for developing composite indicators”, published in the Journal of Open Source Software (JOSS). You can find the paper in all its glory right here.\nAs has been said elsewhere, JOSS follows a really interesting open review and publication system via GitHub. I can safely say it has been the nicest publication experience I have had so far. And that’s not because it was accepted with no modifications. On the contrary, I had to expand the unit test coverage from about 25% up to 80% which took quite a lot of effort, and there were a number of other good issues raised by the reviewers. The reason I liked it is because it was fair and thorough but also quick and efficient. You can see the full review here.\nSo COINr now has a proper citation associated with it, which means that I and my co-authors can be credited for our work. It also has an all-important DOI.\nAt the moment, this is the last paper I am involved in. I have resolved not to get involved in other papers unless I return to an academic job. However, there may be some other interesting things on the horizon for COINr. There is some fairly serious talk of turning it into a Shiny app, which would be very interesting. I can’t reveal other details at the moment since nothing is totally confirmed but stay tuned!"
  },
  {
    "objectID": "posts/2022-09-08_Genesis/index.html",
    "href": "posts/2022-09-08_Genesis/index.html",
    "title": "Genesis",
    "section": "",
    "text": "I thought it was about time I made a personal website, and so here it is.\nThe reality is, in this day and age (yes I’m getting a little old), having a personal web page is very handy for showcasing my work to potential employers, for generating professional collaborations, and for keeping a record of what I’ve done. Instead of boring people with a long CV, I can just point people to this web page and they can read as much or as little as they want.\nI’m not sure yet how much blogging I will do here. I already have a series of blog posts on composite indicators at another professional page (with some colleagues). I also have a consultancy site here but under the guise of “bluefox”, and there are other blog posts there. I may end up porting some of those here.\nAt the end of the day, blogging is a lot like shouting into the infinite void of space. Most of the time no one is listening, but it can be fun anyway!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "William Becker",
    "section": "",
    "text": "GitHub\n  \n  \n    \n     LinkedIn\n  \n\n      \nI’ve led data-driven research projects for international organisations since 2011 on topics from sustainable development to globalisation."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "William Becker",
    "section": "",
    "text": "LinkedIn\n  \n  \n    \n     Github\n  \n  \n      Google Scholar\n  \n  \n      ResearchGate\n  \n\n  \n  \nI am a policy-oriented data scientist currently based in North Italy. I work for international organisations like the European Commission, UN agencies, policy consultancies and non-profit organisations on topics from GHG emissions and sustainable development to skills systems and innovation.\nI’m eternally curious about learning new things, and this has led me to work in many different fields. I’ve worked on high-impact projects with dozens of international organisations.\nThroughout my career I’ve discovered what I really enjoy:\n\nWorking with interesting people\nTackling challenging and worthwhile problems\nCreating things: tools, books, reports, training courses\nThe satisfaction of doing something well\nLearning new things and teaching others\n\nTo find out more about my work, see my recent projects. For my research, see my publications list.\n\n CV downloads\nShort CV Europass CV Academic CV"
  },
  {
    "objectID": "about.html#fa-building-experience",
    "href": "about.html#fa-building-experience",
    "title": "William Becker",
    "section": "     Experience",
    "text": "Experience\n\n\n\n\n\n\nData science/policy consultant\n\n\n\n2020-present\nStatistical, software and data research for international organisations including the European Commission, UN agencies, consultantcies and non-profits. I lead projects from client/stakeholder engagement and workshops through data analytics and web visualisation.\nSee more on the projects page.\n\n\n\n\n\n\n\n\nSenior data/policy analyst\n\n\n\n2014 - 2020: European Commission, Joint Research Centre\nSupporting the European Commission in international data analysis, indicator frameworks, and analysis of uncertainty and sensitivity/robustness. I was a senior researcher simultaneously in the European Commission’s Competence Centre for Composite Indicators and Scoreboards, as well as the Competence Centre for Modelling, which are both cross-cutting groups supporting multiple policy areas. I worked extensively with many different departments of the European Commission (JRC, EEAS, BUDG, GROW, SG, RSB, REGIO, etc), leading and supporting projects and training colleagues, as well as with a wide range of international organisations.\n\n\n\n\n\n\n\n\nScientific/technical project officer\n\n\n\n2011 - 2014: European Commission, Joint Research Centre\nI worked in the Econometrics and Applied Statistics unit of the JRC: my role was to provide statistical support to the rest of the European Commission, particularly regarding impact assessments, indicators and modelling."
  },
  {
    "objectID": "about.html#fa-graduation-cap-education",
    "href": "about.html#fa-graduation-cap-education",
    "title": "William Becker",
    "section": "   Education",
    "text": "Education\nDownload my CVs using the buttons above for more details.\n\nPhD Mechanical Engineering | University of Sheffield, UK, 2006 – 2011: PhD in Mechanical Engineering and applied machine learning and Bayesian stats. Thesis entitled: Uncertainty propagation through large nonlinear models.\nMEng Mechanical Engineering | University of Sheffield, UK, 2002 – 2006: MEng in Mechanical Engineering with Spanish. Included one year as an Erasmus student at the University of Seville, Spain."
  },
  {
    "objectID": "about.html#fa-link-links",
    "href": "about.html#fa-link-links",
    "title": "William Becker",
    "section": "   Links",
    "text": "Links\nHere are a few links with more info and projects related to me in a professional context.\n\nI work on indicator and data projects with an excellent team of professionals. Find out more at our website here, including my blog pages and details about my colleagues.\nSee my (recent) code at my GitHub page.\nMy older personal/professional website is still up here.\nLinkedIn\nResearchgate and Google Scholar"
  },
  {
    "objectID": "about.html#fa-sun-outside-work",
    "href": "about.html#fa-sun-outside-work",
    "title": "William Becker",
    "section": "    Outside work",
    "text": "Outside work\nI am a creative person and a musician and I enjoy playing guitar and (trying to) sing. I also love sports, including running, skiing, swimming and hiking. I spend a lot of time with my family, but also like building things and growing organic food in the garden.\nA couple of voluntary activities I am involved in:\n\nI manage children’s and adult’s music courses at the JRC Association for Music Makers.\nI founded and run a Repair Cafe in Ispra where we help people fix and reuse broken items rather than throwing them away."
  },
  {
    "objectID": "posts/2022-03-01_OccamsRazor/index.html",
    "href": "posts/2022-03-01_OccamsRazor/index.html",
    "title": "Occam’s Razor",
    "section": "",
    "text": "So far in my few posts in this blog I’ve been writing about indicators. Actually I only started working in indicators around 2015. I found that the topic suits me because it is a blend of statistics/data analysis and qualitative work (writing, conceptualising and so on), and I like things that are not too narrowly focused.\nBefore that (and still now) I was/am a researcher in sensitivity and uncertainty analysis. Uncertainty analysis is understanding how uncertainties in model inputs affect the results, and sensitivity analysis is a more detailed breakdown of which particular model inputs/assumptions are causing the most uncertainty, and by how much.\nThese topics, combined with some years of experience working in the European Commission, also led me to be generally interested in modelling. I had direct experience building engineering and biomechanical models in my PhD, and came across many different types of models in the Commission, often used for policy impact assessments.\n\nWhat is a model?\nFirst of all, what is a model? Well, as usual there are many ways to divide and classify things, but one distinction is:\n\nPrinciple/process-driven models: these are models that are built based on understanding the physics or processes behind the system. A simple example is Hooke’s Law which describes how a spring extends under a given load. More complex examples are hydrological models and climate models. In all cases, the model is built based on some encoding of the physics or processes driving the system.\nData-driven models: in these models, the system is treated much like a black box. Instead, we use a set of measured system inputs and outputs, and try to build a statistical mapping between the two. A linear regression is a simple example, but more complex examples are Gaussian processes, neural networks, deep learning and so on. What they have in common is that the modelling simply tries to replicate the input/output relationship, rather than trying to model any particular physical process.\n\nNo doubt many people would dispute the nuances of those definitions, but I think that the core concept is solid. However, the two categories are not distinct, and in fact will overlap to some extent. At the end of the day, both categories are a system of equations, and both usually have to be calibrated or fitted in some way. This discussion could go on for a while so let’s leave it at that for now.\n\n\nElementary, my dear Occam\nOccam’s Razor is one of those heuristics that seems to apply everywhere. According to Wikipedia, it can be defined as:\n\nthe problem-solving principle that “entities should not be multiplied without necessity”, or more simply, the simplest explanation is usually the right one.\n\nWhat has this got to do with modelling? Well, everything points to the fact that the simplest model that explains the data/process is the best.\nThis idea is well-known in statistical modelling (i.e. category 2 of the taxonomy above). You might have heard of the “bias-variance trade off”: this is the idea that there is a balance to be struck between underfitting and overfitting a set of data. Underfitting means that the model is too simple to explain the data/process, whereas overfitting means the opposite: the model gives too much weight to individual observations, rather than focusing on the underlying process.\nThe general idea is that most of the time, when you are modelling data, you expect a relationship along the lines of:\n\\[ y = f(x) + \\epsilon \\] where \\(y\\) is the variable you want to model, \\(x\\) is the variable, or set of variables that explain \\(y\\), and \\(\\epsilon\\) (which can also be a function of \\(x\\)) is a summary of other “things” that contribute to \\(y\\) but you are not explicitly trying to model. The “things” can errors due to measurement, but they can also be other variables that you are not able to measure, or you prefer not to include in this particular modelling exercise.\nThe point is that what you want to understand and isolate is \\(f(x)\\), not \\(\\epsilon\\). If your model starts to include elements of \\(\\epsilon\\), then you have a mix of the two quantities, and this makes it difficult/impossible to (a) understand the relationship between \\(y\\) and \\(f(x)\\), and (b) make predictions of \\(y\\) at unobserved values of \\(x\\). Occam’s Razor can be statistically proven - a nice example is in David Mackay’s excellent Information Theory, Inference, and Learning Algorithms book - see Chapter 28.\nAnyway, let’s visualise this idea. Here’s some data: \\(x\\) is random numbers, \\(y = 2x + \\epsilon\\), where $ $ is normally-distributed noise.\n\nlibrary(plotly)\nx &lt;- runif(20) %&gt;% sort() # random numbers (sorted to avoid problems in plotting)\ny &lt;- 2*x + rnorm(20)*0.5 # create y and add noise\ndf &lt;- data.frame(x, y)\nfig &lt;- plot_ly(data = df, x = ~x, y = ~y) # plot\nfig\n\n\n\n\n\nNow let’s consider two possibilities. We want to know how \\(y\\) is related to \\(x\\). In the first case, we fit a straight line through the data (this is cheating because it is the real relationship).\n\nf &lt;- lm(y ~ x, data=df) # fit linear regression\ndf &lt;- cbind(df,ylin=f$fitted.values) # add to data frame\n\n# plot\nfig &lt;- plot_ly(data = df, x = ~x)\nfig &lt;- fig %&gt;% add_trace(y = ~y, name = 'Data',mode = 'markers')\nfig &lt;- fig %&gt;% add_trace(y = ~ylin, name = 'Linear fit',mode = 'lines')\nfig\n\n\n\n\n\nLooks good, and it is close to the actual relationship. But in practice, if all we have is a set of \\(x\\) and \\(y\\) values, we wouldn’t know whether the relationship between \\(x\\) and \\(y\\) is linear, or something more complicated. We might consider fitting a higher-order polynomial, for example. This might seem like a good idea, because after all, a linear model is a special case of a higher order polynomial, so we can’t lose anything by making it more complicated - it will still provide the best fit, right?\n\nf2 &lt;- lm(y ~ poly(x,5), data=df) # fit 5th-order polynomial\ndf &lt;- cbind(df, ypoly=f2$fitted.values, ytrue = 2*x) # add to data frame\n\n# plot\nfig &lt;- plot_ly(data = df, x = ~x)\nfig &lt;- fig %&gt;% add_trace(y = ~y, name = 'Data',mode = 'markers')\nfig &lt;- fig %&gt;% add_trace(y = ~ytrue, name = 'True f(x)',mode = 'lines')\nfig &lt;- fig %&gt;% add_trace(y = ~ylin, name = 'Linear fit',mode = 'lines')\nfig &lt;- fig %&gt;% add_trace(y = ~ypoly, name = '5th-order poly fit',mode = 'lines')\nfig\n\n\n\n\n\nAs you can see, this was not a good idea. The higher-order model overfits the data. Because it has more flexibility in its shape, it is able to get closer to some of the outlying points, but by doing so it is confusing the noise with the underlying linear relationship, \\(f(x)\\).\n\n\nKeep on Occam in the Real World\nOK, so outside of regression, what’s the implication? Well, as we have discussed here, any model, be it a large physical model or a simple regression, is a mapping of inputs to outputs. It aims to emulate a system. If your model is calibrated to observations (if it’s not, that’s a problem in itself), then you are in exactly the same situation as the example above. In short, if you build a hugely complicated model you run the risk of overfitting it to observation data, which actually results in poorer prediction capability than a simple model.\nIt’s important to point out amid all this complex-model-bashing that this is not about ignoring complexity, but striking a balance. There is as much risk in underfitting as overfitting. Clearly, you can’t model a complex nonlinear system with a linear model either. So, what to do?\nLuckily these problems have been studied by very clever people for many years, in a field known as model selection, and there are a range of tools such as information criterion, Bayes factors, cross-validation and more.\nA problem here is that while it is easy in statistical modelling to build many different alternative models and compare them, in process-driven models this is much more difficult. While alternative models can be compared, it is probably worth keeping in mind that adding more and more complexity to a model, and throwing more computing power at it, does not necessarily reduce the uncertainty. To make that point, consider how the uncertainty in climate sensitivity has changed over the last 30 years:\n\n1979: 1.5-4.5C [National Academy of Sciences]\n1990: 1.5-4.0C [IPCC first report]\n1996: 1.5-4.0C [IPCC second report]\n2007: 2.0-4.5C [IPCC fourth report]\n2014: 1.5-4.5C [IPCC fifth report]\n\nSince 1979, computing power has increased at least a hundredfold. But the estimated uncertainty has actually remained the same.\n\n\nFinally\n\n\n\nModel tradeoff\n\n\nThis is a slightly whimsical slide that I’ve used in the past to elaborate on this problem. A simple model is further away from reality in terms of “structural uncertainty”, i.e. the uncertainty due to the fact that the model simplifies the complexities of the real system. But there is actually less uncertainty in its parameters because there are less parameters. In the linear model, there are only two parameters.\nWhereas, if we go to a more complex model, it becomes closer to “reality” in that it inludes more of the complexities of the real system, but now we have more parameters to fit, so there can actually be more parametric uncertainty! In the fifth-order polynomial used above, there are 6 parameters, and it was clear that it actually caused more trouble than it was worth.\nOk that’s it for now folks. This is a long topic and I have other work to get on with. I intend to continue this series on the ins and outs of modelling and uncertainty.\nImage by Clker-Free-Vector-Images from Pixabay"
  },
  {
    "objectID": "posts/2022-09-14_Peer_Review/index.html",
    "href": "posts/2022-09-14_Peer_Review/index.html",
    "title": "Open peer review: a better way?",
    "section": "",
    "text": "If you have worked in academia for any length of time at all, you will know a bit about peer review, and will most likely have had some frustrating experiences along the way.\nBut for non-academics, what is peer review anyway? Well, first, it’s necessary to explain that much of an academic’s worth is measured by the number (and to some extent, the quality) of academic publications. A publication is basically a report of some research done by the academic, usually of around 6000-10000 words. The “manuscript” (yes for some reason we have to pretend we’re in Ancient Egypt) is submitted to an appropriate journal, it is reviewed by “peer review”, and then if it is accepted, it is published, and the academic and his/her colleagues get a juicy publication point and accompanying citations to beef up their reputation.\nMore or less, the process of publication looks like this:\nThis is a simplified version of the process, and the review part typically takes some months, but may take years. Importantly, the large majority of reviews are done confidentially, so only the editor, the reviewers and the author, see what happened. Often the reviews are blind (the reviewers see the names of the authors but not the other way around), or double-blind (both authors and reviewers don’t know the names of each other, everything is anonymised). I’ll return to this point."
  },
  {
    "objectID": "posts/2022-09-14_Peer_Review/index.html#hostile-reviewers",
    "href": "posts/2022-09-14_Peer_Review/index.html#hostile-reviewers",
    "title": "Open peer review: a better way?",
    "section": "Hostile reviewers",
    "text": "Hostile reviewers\nEvery academic has come up against hostile reviewers. The review process is not meant to be easy, but a surprising number of reviewers seem to nit-pick to an extent that seems to go beyond what is reasonable. They may insist on extensive but unnecessary modifications, or are constantly unsatisfied with revisions. In an ideal world the editor would spot these over-zealous reviewers, but editors are busy. Sometimes such reviews may be due to the fact that the reviewer is from a competing institution, and therefore there is little reason (apart from professionalism and honesty) for them to play fair. This problem is enabled by the fact that the review process is done behind closed doors, so there are virtually no consequences if reviewers don’t behave themselves.\nBlind and double-blind reviews should help vindictive attacks between rivals in theory, but in practice many research fields are small enough that it is often fairly obvious, even without names, to know who wrote the paper (if you are the reviewer) and to know who the reviewers are (if you are the author)."
  },
  {
    "objectID": "posts/2022-09-14_Peer_Review/index.html#friendly-reviewers",
    "href": "posts/2022-09-14_Peer_Review/index.html#friendly-reviewers",
    "title": "Open peer review: a better way?",
    "section": "Friendly reviewers",
    "text": "Friendly reviewers\nAt the other end of the spectrum are the reviewers who are your mates. To save editor time (and ostensibly to find suitable reviewers), in many journals authors are allowed to suggest reviewers for their paper. In theory, reviewers are not supposed to have any close connection with the authors, but in practice, editors have to deal with many papers and reviewers are scarce. So often, the authors’ recommended reviewers end up reviewing the paper.\nClearly the problem is that if the authors are not playing cricket, so to speak, they can just recommend their friends as reviewers. Depending on the level of integrity, these reviewers may give an overly-soft review or even accept the paper outright with no modifications. The result is that the paper hasn’t really been through a real peer review. Again, this problem is facilitated by the fact that the review is not public."
  },
  {
    "objectID": "posts/2022-09-14_Peer_Review/index.html#publication-for-citations",
    "href": "posts/2022-09-14_Peer_Review/index.html#publication-for-citations",
    "title": "Open peer review: a better way?",
    "section": "Publication for citations",
    "text": "Publication for citations\nA fairly innocent-sounding comment is when a reviewer recommends that the author make some further citations to specific papers, a.k.a. “relevant literature”, possibly to “improve the context of the work”. The catch is that all of these citations happen to be the reviewer’s papers, or else those of their friends. This puts the authors in an awkward position: they can cite the proposed papers, which is easy to do, and that will appease the reviewer and bring them closer to publication. Alternatively, they could contest the recommended citations, but this will likely delay the process and could aggravate the reviewer. By far the easiest option is to just cite the papers - is it worth risking possibly months of delays? But it is irksome to have to “pay passage” to the reviewer in this way, and is obviously not ethical."
  },
  {
    "objectID": "posts/2022-09-14_Peer_Review/index.html#lazy-reviews",
    "href": "posts/2022-09-14_Peer_Review/index.html#lazy-reviews",
    "title": "Open peer review: a better way?",
    "section": "Lazy reviews",
    "text": "Lazy reviews\nA proper review of a paper takes time, sometimes rather a long time. Apart from anything else, many research papers are complex and take time to understand, even for experts. You should carefully read the whole paper and try to spot any flaws in the methodology, mistakes in equations, and make sure it is written clearly and concisely. You should make as many suggestions as possible to improve the paper (without being nit-picky - see above), and be prepared to spend time communicating with the authors after successive revisions. Sometimes you have to check the cited work to make sure the citations actually support the statements made in the paper.\nSince reviews are unpaid and uncredited, it is easy for them to fall low on the priority list of the reviewers’ tasks, especially in busy periods. This can sometimes lead to very lazy reviews, where a reviewer writes a short review to simply tick it off the list. In one case, a reviewer of my paper simply copied the abstract of the paper (presenting it as his/her review) and added one vague sentence saying that it wasn’t good enough. It was clear that the reviewer had not even read the paper and had probably spent five minutes compiling the “review”.\nThe issue is that of course it is far easier to reject a paper on vague grounds, rather than attempt to read it properly, understand it, and offer constructive comments."
  },
  {
    "objectID": "posts/2022-09-14_Peer_Review/index.html#the-never-ending-story",
    "href": "posts/2022-09-14_Peer_Review/index.html#the-never-ending-story",
    "title": "Open peer review: a better way?",
    "section": "The never-ending story",
    "text": "The never-ending story\nReviewing takes time, as we have seen. But there should be reasonable limits. To describe a personal example, the research for one paper of mine was completed in 2014. We had a hard time finding a suitable home for the work because it was a fusion of two fields (sensitivity analysis and econometrics). At one point it was stuck in one journal for a whole year with no response from the editor. It was rejected from a few other journals because of the topic and other reasons. Finally we submitted it to another journal, where it took two and a half years to be reviewed. In total, it took us seven years to get the paper published.\nI’m not claiming that the paper had a divine right to publication, and in some cases reviewers had made reasonable points for rejecting the paper, which we subsequently addressed. But if research takes years to review, that is a problem for the authors and for the wider research field because there is such a huge lag in making new work visible. It means that published literature doesn’t represent the state of the art, but rather the state of the art a couple of years ago, or more."
  },
  {
    "objectID": "posts/2022-12-05_SAMOweb_plus/index.html",
    "href": "posts/2022-12-05_SAMOweb_plus/index.html",
    "title": "New projects plus website",
    "section": "",
    "text": "It’s difficult to make a post about everything, so here’s a summary of some recent things."
  },
  {
    "objectID": "posts/2022-12-05_SAMOweb_plus/index.html#samo-website",
    "href": "posts/2022-12-05_SAMOweb_plus/index.html#samo-website",
    "title": "New projects plus website",
    "section": "SAMO Website",
    "text": "SAMO Website\nFirst, I just launched today the group website for the Sensitivity Analysis of Model Output (SAMO) group. I started this over a year ago, but finally decided to get it properly over the finish line. SAMO is an international group of researchers and academics working on sensitivity analysis in different fields, and organises the SAMO conference every three years. I’ve been to the conference several times and am a member of the SAMO board. If you want to know more, hmm where can you go to find out? Oh yes, the new website of course!"
  },
  {
    "objectID": "posts/2022-12-05_SAMOweb_plus/index.html#projects",
    "href": "posts/2022-12-05_SAMOweb_plus/index.html#projects",
    "title": "New projects plus website",
    "section": "Projects",
    "text": "Projects\nThings are definitely starting to get busy now. Which is why I decided to finish the SAMO website before I have no time for it!\nI’ve been continuing my work with the great people at the Global Innovation Index, implementing new features, improving test coverage, and generally making the package more useful and robust. I’m also just about to start an audit of the Vietnam regional innovation index (a kind of spinoff of the GII), which is a new index, yet to be launched.\nVery recently, as mentioned elsewhere, I have started working on a very interesting project: a Shiny App to wrap the COINr package in for the good people at FIND. I’ve been preparing the mockups. This could be a very interesting app for many people but will also be non-trivial to develop. I am working with some very skilled developers though so it is looking promising.\nElsewhere several contracts are (probably) about to start. Some work for the JRC on impact assessments, some other work for the JRC on air pollution data analysis, and an index for the UNHCR in Guatemala. Can’t give too many details yet but these things should happen. I also have some other (less certain) stuff in the pipeline.\nSo, I will be very busy in the coming months, working on all kinds of interesting topics!"
  },
  {
    "objectID": "posts/2023-01-11_Teams/index.html",
    "href": "posts/2023-01-11_Teams/index.html",
    "title": "I don’t like MS Teams",
    "section": "",
    "text": "Sorry, this has to be said to help with my emotional well being because Teams has driven me to the depths of despair and this is the only way I can think of to begin some kind of cathartic healing process.\n(disclaimer: please take the following rant in the humorous way that it is intended) :innocent:\nI work as a freelance consultant for multiple organisations. I also have my own Microsoft account. Every time I am invited to collaborate on a project with a new organisation I have sleepless nights because I know what’s coming. It’s only a matter of time. The dreaded email. Those awful words.\n“Let’s connect on Teams”.\nSo yet again, I have to go through the same process. Click on the link emailed to me. MS assumes I want to join with a different account that I have used for a different org and tries to sign me in with that org. Fails. Offers no way to sign out and to join the actual org that invited me. Sometimes I have managed to sign out, MS says I’m signed out. Click the link again, no actually I wasn’t signed out because EXACTLY the same thing happens. So then I open link in incognito mode. About 50% of the time I manage to actually join the meeting, the other half not, with no explanation of what the problem actually is and we end up moving to Zoom or WebEx. Still got no idea now how to join a meeting without opening in incognito mode.\nBut that’s just for a one off meeting. If I want to actually join a “Team”, as a guest, it’s 10x worse. Asked to create an account. But then it starts harping on about work vs personal emails. I end up trying from all kinds of different email addresses, emailing the clients back and forth. Usually face all kinds of dead ends. It asks me to install some stupid app. And/or sends verification codes that don’t work, asks for my phone number, and after I’ve handed over all my personal information, my bank details, DNA samples, embarrassing pictures and whatever else it still gleefully denies access.\nOn some occasions I actually make it into Teams but I can’t see the “Team” I was invited to. Cue more frantic emails with client, client consulting IT department, IT department stumped. After a few hours perhaps we finally get in through randomly exploring every possible combination of emails, settings and any other explanatory variables that come to mind. Having finally cracked the safe, client asks me to look at document X. Discover that I don’t have permission to look at the document (despite it being in the file repository of the team that I’m a member of). Everyone just gives up and moves back to email.\nI can only imagine that Teams was invented as some kind of purgatory for our sins. If that’s the case, I can only say that when I die, I will die with a pure soul because I have atoned one hundredfold for the sins of my life, in tears shed and time lost over Microsoft Teams. And what’s more, I will die happy in the knowledge that in the afterlife, whatever it may be, there will be no Teams. I hope."
  },
  {
    "objectID": "posts/2023-09-08_EDGAR_booklet/index.html",
    "href": "posts/2023-09-08_EDGAR_booklet/index.html",
    "title": "Global emissions data set published",
    "section": "",
    "text": "In September 2023, as part of my work as a data scientist at the Joint Research Centre, I contributed to the GHG emissions of all world countries booklet.\nThe booklet is an annual output of the EDGAR database team (of which I am a member) and provides emissions time series from 1970 until 2022 for GHGs for all countries and for all anthropogenic sectors. EDGAR is used around the world as a highly-detailed, consistent and high-quality data source for research and policy making.\nMy particular role in this endeavour was calculating uncertainties on emissions estimates. This is a fairly complex procedure given the size and complexity of the database, and also due to issues such as skewed distributions and correlations. To do this I built a custom R package which is live-linked to the EDGAR database using SQL drivers. Uncertainties can be explored, visualised and exported internally via a Shiny app.\nI’m quite proud of my contributions so far to the EDGAR project (although these are mostly internal), and pleased to be a part of a team that contributes significantly to climate change research and policy."
  },
  {
    "objectID": "posts/2023-10-10_KSA_workshop/index.html",
    "href": "posts/2023-10-10_KSA_workshop/index.html",
    "title": "2023 Wrap Up",
    "section": "",
    "text": "Work on the Quality Infrastructure for Sustainable Development Index (better written as its acronym QI4SD Index) is warming up again. And not many places are warmer than Riyadh in Saudi Arabia!\nOn 3-4 October I was invited to Riyadh as part of the UNIDO-led team working on the QI4SD Index to present the index methodology to the Saudi Accreditation Center and the Saudi Standards, Metrology and Quality Organization. We spent two days of very interesting and useful discussions, working on ways to improve the index and examining the QI and sustainable development context of Saudi Arabia.\nRiyadh was also a fascinating city to visit and to experience some Saudi culture and hospitality."
  },
  {
    "objectID": "posts/2023-11-17_EIS_bid/index.html",
    "href": "posts/2023-11-17_EIS_bid/index.html",
    "title": "European Innovation Scoreboard",
    "section": "",
    "text": "I have done a bit of writing of project bids in the past but this was the first time that I got more heavily involved. As part of a really talented team (who I won’t mention at this point for privacy reasons) I helped to put together a bid to update and maintain the European Innovation Scoreboard.\nThis is a scoreboard and composite indicator owned by DG-RTD that measures innovation in European countries, and also looks at the sub-national level in the form of the Regional Innovation Scoreboard. The call for tender is a fairly big one and involves a few years of work. My role as usual would be to do the composite indicator calculations.\nOf course we all have our fingers crossed that our bid might be successful. For my part, I have strongly advocated for reproducible development of composite indicators and good data science practice (e.g. programmatic approach, unit testing, use of collaborative platforms like GitHub and so on).\nOther than that it was an interesting experience in compiling a big bid and working as a consortium. It was a lot of work, all the more so because it is prospective. But I think the result was pretty good. So I think we have a fighting chance to make it."
  },
  {
    "objectID": "posts/2023-12-01_FINDApp_update/index.html",
    "href": "posts/2023-12-01_FINDApp_update/index.html",
    "title": "Updates on the FIND composite indicators app",
    "section": "",
    "text": "The Foundation for Innovative New Diagnostics (FIND) is a non-profit organisation which “seeks to ensure equitable access to reliable (medical) diagnosis around the world. Early in 2023 I began working with them to develop a Shiny app which can build composite indicators to help them identify in which countries to direct their resources.\nAfter much hard work and collaboration with talented people, we are nearly ready to release the app. Although the app was developed as a tool for use within FIND, we should be able to release an open-source version of it, which can be installed as an R package, but run as an app.\nThe app is essentially a front end for the COINr package, but also has a number of modifications and tries to strike a balance between flexibility and not overwhelming the user with too many options. Its features include:\n\nUpload of any data set and index structure\nScreening units by data availability\nImputation of missing data\nOutlier treatment\nNormalisation and aggregation\nStats, maps, bar and bubble charts\nUnit profiles\nGlobal sensitivity analysis and reweighting\n\nI leave a couple of screenshots here, and hopefully the app will be made freely available in the near future!"
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Blog",
    "section": "",
    "text": "Here’s what I’ve been doing recently.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\n2023 Wrap Up\n\n\nLooking back on a very busy and interesting year.\n\n\n\n\n\n\nDecember 31, 2023\n\n\n7 min\n\n\n\n\n\n\n  \n\n\n\n\nUpdates on the FIND composite indicators app\n\n\nWrapping up the composite indicators app project for release.\n\n\n\n\n\n\nDecember 30, 2023\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nUpdates of the WEF Nexus Index\n\n\nUpdating the WEF Nexus Index with the latest data.\n\n\n\n\n\n\nNovember 20, 2023\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nEuropean Innovation Scoreboard\n\n\nIn which we put in a bid to update and maintain this index.\n\n\n\n\n\n\nNovember 17, 2023\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nExpert group meeting on quality infrastructure in Vienna\n\n\nNovember 14-15, Vienna, Austria. Expert group meeting on the QI4SD Index in Vienna with representatives from INetQI organisations and national institutions.\n\n\n\n\n\n\nNovember 15, 2023\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\n2023 Wrap Up\n\n\nOctober 3-4, Riyadh, Saudi Arabia. A workshop to discuss the QI4SD Index.\n\n\n\n\n\n\nOctober 5, 2023\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nCOIN training on composite indicators\n\n\nMy lectures on robustness in composite indicators and the COINr package.\n\n\n\n\n\n\nSeptember 28, 2023\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nGlobal emissions data set published\n\n\nWe published the JRC’s annual report on greenhouse gas emissions of all countries in the world.\n\n\n\n\n\n\nSeptember 8, 2023\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nA2SIT App launched for UNHCR\n\n\nThe Admin-2 Severity Index Tool was completed in its beta state and launched for UNHCR Guatemala.\n\n\n\n\n\n\nJuly 28, 2023\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nFreelance data science: a two-year review\n\n\nThe story of a two-year freelance journey and its pros and cons.\n\n\n\n\n\n\nDecember 16, 2022\n\n\n13 min\n\n\n\n\n\n\n  \n\n\n\n\nNew projects plus website\n\n\nRecently I built a website, and I’m starting several new projects soon. Things starting to get very busy!\n\n\n\n\n\n\nDecember 5, 2022\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nI don’t like MS Teams\n\n\nWhy I really really don’t like Microsoft Teams in one short rant :smile:\n\n\n\n\n\n\nDecember 1, 2022\n\n\n3 min\n\n\n\n\n\n\n  \n\n\n\n\nPaper for COINr published\n\n\nA little bit about my new paper and why it is a Good Thing.\n\n\n\n\n\n\nOctober 11, 2022\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nOpen peer review: a better way?\n\n\nUsing Github and transparent open review to improve the peer review process.\n\n\n\n\n\n\nSeptember 14, 2022\n\n\n14 min\n\n\n\n\n\n\n  \n\n\n\n\nGenesis\n\n\nNew personal website launched! :rocket:\n\n\n\n\n\n\nSeptember 8, 2022\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nOccam’s Razor\n\n\nAnd its many applications.\n\n\n\n\n\n\nMarch 1, 2022\n\n\n8 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/ASEM/index.html",
    "href": "projects/ASEM/index.html",
    "title": "Asia-Europe Connectivity",
    "section": "",
    "text": "I co-led a major multi-year project to support the European Commission’s External Action Service in measuring international links between Asian and European countries. The work supported the high-level Asia-Europe Meeting in which heads of state of Asian and European countries meet to explore how to better connect on issues such as trade, education, research, defense and global issues such as climate change and health.\nThe work involved:\n\nExtensive client consultation\nOrganising two international workshops with topical experts from Asia and Europe\nCollecting and cleaning extensive amounts of data\nStatistical and multivariate analysis\nMeeting client needs while respecting technical rigour and practical considerations\nWriting and publication of a flagship report\nDesigning an interactive data exploration platform\nPresenting work to senior stakeholders (up to ministerial level)\nNavigating a sensitive political environment and respecting cultural differences\n\nTo find out more about this work, see the ASEM Sustainable Connectivity Portal.\nThe work also resulted in a spin-off international research conference (AESCON), which I co-founded and co-organised.\nSee also our academic paper on this topic."
  },
  {
    "objectID": "projects/COINr/index.html",
    "href": "projects/COINr/index.html",
    "title": "COINr: An R package for composite indicators",
    "section": "",
    "text": "COINr is a high-level R package which is the first fully-flexible development and analysis environment for composite indicators and scoreboards. The main features can be summarised as features for building, features for analysis and features for visualisation and presentation.\nI am the author, designer and developer of this package. It is used worldwide by universities and international organisations to develop and analyse composite indicators, including the European Commission’s Joint Research Centre, United Nations agencies and many others.\nCOINr was originally developed under contract with the European Commission’s Joint Research Centre, but has since been developed much futher under other contracts that I have worked on, and in my own time.\nFor further reading, see:\n\nThe main COINr website and documentation\nGithub repo\nCRAN page\nOnline book (this is now outdated and refers to an older syntax)\nPaper published in the Journal of Open Source Software"
  },
  {
    "objectID": "projects/COINtool/index.html",
    "href": "projects/COINtool/index.html",
    "title": "COIN Tool",
    "section": "",
    "text": "The COIN Tool is an advanced Excel tool for building and auditing composite indicators. While working at the European Commission’s Joint Research Centre, I collaborated with a professional developer to bring the tool from a prototype to release. Aside from contributing to the development of the tool, I am the main author of the documentation.\nThe COIN Tool is now used worldwide as an accessible development tool by academics and researchers in policy making. Its documentation, can be found here."
  },
  {
    "objectID": "projects/ESI/index.html",
    "href": "projects/ESI/index.html",
    "title": "European Skills Index",
    "section": "",
    "text": "The European Skills Index (ESI) is a well-established composite indicator that is produced by Cedefop, the European agency which promotes vocational and education training. It aims to measure skills systems at the national level in European countries.\nAs of 2023 I was part of a consortium that successfully won the bid to update and potentially tweak/improve the ESI for the next few years.\nThe next iteration of the ESI will be launched in 2024, and I am in charge of the main ESI index calculations. Naturally, I am using the COINr package which is (even though I am mega-biased) the best tool out there for building reproducible composite indicators! Some particular improvements that I am making are:\n\nFully-reproducible data pipeline based on APIs as much as possible\nProgrammatic data and methodology validation\nResults calculated using COINr in Quarto documents: fully transparent and easily portable.\n\nThe idea here is to modernise the ESI calculation and make it super easy to come back in future years for updates.\nAt the time of writing we are about to calculate the final results. Of course there will be plenty to do afterwards in reporting, but for now we are on track."
  },
  {
    "objectID": "projects/IA/index.html",
    "href": "projects/IA/index.html",
    "title": "Impact assessment",
    "section": "",
    "text": "Impact assessment is the ex-ante assessment of the expected impacts of a policy. Usually this is done to compare several policy options, and the option which best meets the criteria will be chosen.\nOver several years I supported European impact assessments in several ways:\n\nAuthoring the European Commission’s Better Regulation Guidelines, which guide all European impact assessments, on the topics of modelling and sensitivity/uncertainty analysis.\nReviewing the statistical/data aspects of specific impact assessments, on topics including gender equality, GPS, long-term care and liability of nuclear energy companies.\nProviding training to Commission staff on my topics of expertise, especially on dealing with uncertainty in modelling."
  },
  {
    "objectID": "projects/other/index.html",
    "href": "projects/other/index.html",
    "title": "Other projects",
    "section": "",
    "text": "I have participated in many projects that are too many to list individually. A few can be mentioned here, in list format:\n\nMeasuring culture and creativity in European cities\nTracking adherence to chemical regulations\nMeasuring progress towards European sustainable development objectives\nAdvising on metrics for African policy making for the welfare of children\nTechnical input for metrics on financial secrecy and tax havens\nAuditing an index on global talent competitiveness\nTechnical input on sustainable development metrics\nAnalysis of the macroeconomic imbalance procedure\n\nSee also my academic research, and other technical reports from my days at the European Commission. My Researchgate profile has also further published works."
  },
  {
    "objectID": "projects/Training/index.html",
    "href": "projects/Training/index.html",
    "title": "Training",
    "section": "",
    "text": "I have been an enthusiastic teacher and trainer for many years. This includes:\n\nLeading and organising stats/data training courses for the European Commission\nTraining researchers and colleagues on composite indicators\nTraining researchers and colleagues on sensitivity and uncertainty analysis (see here and earlier editions)\nPrivate tuition on statistical programming, data analysis and indicators"
  },
  {
    "objectID": "projects/Vietnam/index.html",
    "href": "projects/Vietnam/index.html",
    "title": "Vietnam provincial innovation index",
    "section": "",
    "text": "The Vietnam Provincial Innovation Index is a new composite indicator developed by the Vietnam Ministry of Science and Technology in 2022, which aims to measure innovation at the provincial level in Vietnam. The index has been created in collaboration with the World Intellectual Property Organisation, who are the developers of the very well-known Global Innovation Index, which I have also helped out with on several occasions!\nIn November/December 2022 I was contracted to perform an independent audit of the index, including data and weighting checks, correlation and multivariate analysis, a review of the methodology and sensitivity and uncertainty analysis. I used the COINr package for the job, and since the developers were anyway using the package themselves to build the index, it was fairly easy to dig deep into the data and help out with one or two technical problems."
  },
  {
    "objectID": "publications/2018_SAScreening/index.html",
    "href": "publications/2018_SAScreening/index.html",
    "title": "Sensitivity analysis approaches to high-dimensional screening problems at low sample size",
    "section": "",
    "text": "About\nSensitivity analysis is an essential tool in the development of robust models for engineering, physical sciences, economics and policy-making, but typically requires running the model a large number of times in order to estimate sensitivity measures. While statistical emulators allow sensitivity analysis even on complex models, they only perform well with a moderately low number of model inputs: in higher dimensional problems they tend to require a restrictively high number of model runs unless the model is relatively linear. Therefore, an open question is how to tackle sensitivity problems in higher dimensionalities, at very low sample sizes. This article examines the relative performance of four sampling-based measures which can be used in such high-dimensional nonlinear problems. The measures tested are the Sobol’ total sensitivity indices, the absolute mean of elementary effects, a derivative-based global sensitivity measure, and a modified derivative-based measure. Performance is assessed in a ‘screening’ context, by assessing the ability of each measure to identify influential and non-influential inputs on a wide variety of test functions at different dimensionalities. The results show that the best-performing measure in the screening context is dependent on the model or function, but derivative-based measures have a significant potential at low sample sizes that is currently not widely recognised."
  },
  {
    "objectID": "publications/2019_SAgrouping/index.html",
    "href": "publications/2019_SAgrouping/index.html",
    "title": "Global sensitivity analysis for high-dimensional problems: How to objectively group factors and measure robustness and convergence while reducing computational cost",
    "section": "",
    "text": "About\nDynamical earth and environmental systems models are typically computationally intensive and highly parameterized with many uncertain parameters. Together, these characteristics severely limit the applicability of Global Sensitivity Analysis (GSA) to high-dimensional models because very large numbers of model runs are typically required to achieve convergence and provide a robust assessment. Paradoxically, only 30 percent of GSA applications in the environmental modelling literature have investigated models with more than 20 parameters, suggesting that GSA is under-utilized on problems for which it should prove most useful. We develop a novel grouping strategy, based on bootstrap-based clustering, that enables efficient application of GSA to high-dimensional models. We also provide a new measure of robustness that assesses GSA stability and convergence. For two models, having 50 and 111 parameters, we show that grouping-enabled GSA provides results that are highly robust to sampling variability, while converging with a much smaller number of model runs."
  },
  {
    "objectID": "publications/2020_bioecon/index.html",
    "href": "publications/2020_bioecon/index.html",
    "title": "Development of a bioeconomy monitoring framework for the European Union: An integrative and collaborative approach",
    "section": "",
    "text": "About\nThe EU Bioeconomy Strategy, updated in 2018, in its Action Plan pledges an EU-wide, internationally coherent monitoring system to track economic, environmental and social progress towards a sustainable bioeconomy. This paper presents the approach taken by the European Commission’s (EC) Joint Research Centre (JRC) to develop such a system. To accomplish this, we capitalise on (1) the experiences of existing indicator frameworks; (2) stakeholder knowledge and expectations; and (3) national experiences and expertise. This approach is taken to ensure coherence with other bioeconomy-related European monitoring frameworks, the usefulness for decision-making and consistency with national and international initiatives to monitor the bioeconomy. We develop a conceptual framework, based on the definition of a sustainable bioeconomy as stated in the Strategy, for a holistic analysis of the trends in the bioeconomy sectors, following the three pillars of sustainability (economy, society and environment). From this conceptual framework, we derive an implementation framework that aims to highlight the synergies and trade-offs across the five objectives of the Bioeconomy Strategy in a coherent way. The EU Bioeconomy Monitoring System will be publicly available on the web platform of the EC Knowledge Centre for Bioeconomy.\n\nDashboards for the monitoring system are now available here."
  },
  {
    "objectID": "publications/2020_Metafunc/index.html",
    "href": "publications/2020_Metafunc/index.html",
    "title": "Metafunctions for benchmarking in sensitivity analysis",
    "section": "",
    "text": "About\nComparison studies of global sensitivity analysis (GSA) approaches are limited in that they are performed on a single model or a small set of test functions, with a limited set of sample sizes and dimensionalities. This work introduces a flexible ‘metafunction’ framework to benchmarking which randomly generates test problems of varying dimensionality and functional form using random combinations of plausible basis functions, and a range of sample sizes. The metafunction is tuned to mimic the characteristics of real models, in terms of the type of model response and the proportion of active model inputs. To demonstrate the framework, a comprehensive comparison of ten GSA approaches is performed in the screening setting, considering functions with up to 100 dimensions and up to 1000 model runs. The methods examined range from recent metamodelling approaches to elementary effects and Monte Carlo estimators of the Sobol’ total effect index. The results give a comparison in unprecedented depth, and show that on average and in the setting investigated, Monte Carlo estimators, particularly the VARS estimator, outperform metamodels. Indicatively, metamodels become competitive at around 10–20 runs per model input, but at lower ratios sampling-based approaches are more effective as a screening tool.\n\nSupporting code is found here, and the metafunction is integrated into the sobolsens package in R."
  },
  {
    "objectID": "publications/2021_ASEM/index.html",
    "href": "publications/2021_ASEM/index.html",
    "title": "Exploring the link between Asia and Europe connectivity and sustainable development",
    "section": "",
    "text": "About\nAsia and Europe have made connectivity between people, businesses and institutions a top political priority in the frame of the Asia-Europe Meeting (ASEM) intergovernmental cooperation forum. In the ASEM context, policy leaders agreed that improving connectivity between countries should contribute to achieve the Sustainable Development Goals. Connectivity is a complex concept involving multiple dimensions. Yet in order to provide clear data-driven evidence to support policymaking on Asia-Europe sustainable connectivity, this concept calls for a measurement framework. The mismatch between the politically adopted definition of sustainable connectivity and existing metrics, led to the development of the two indexes described in this paper. Taken together, they help to explore and understand the relationship between connectivity and sustainability. The results suggest that connectivity and sustainability policy agendas have the potential to mutually reinforce one another. Higher values in connectivity are strongly associated with higher values in the social dimension of sustainability. There are evident gaps between European and Asian nations in terms of connectivity and sustainability. However, both continents are underpinned by the common challenge of reducing the environmental impacts of connectivity without neglecting economic/financial sustainability aspects, while at the same time ensuring that benefits will accrue to society at large.\n\nSee the project webpage at the ASEM Sustainable Connectivity Portal. See also AESCON, the follow-up conference to this project."
  },
  {
    "objectID": "publications/2021_ModelSel/index.html",
    "href": "publications/2021_ModelSel/index.html",
    "title": "Variable Selection in Regression Models Using Global Sensitivity Analysis",
    "section": "",
    "text": "About\nGlobal sensitivity analysis is primarily used to investigate the effects of uncertainties in the input variables of physical models on the model output. This work investigates the use of global sensitivity analysis tools in the context of variable selection in regression models. Specifically, a global sensitivity measure is applied to a criterion of model fit, hence defining a ranking of regressors by importance; a testing sequence based on the ‘Pantula-principle’ is then applied to the corresponding nested submodels, obtaining a novel model-selection method. The approach is demonstrated on a growth regression case study, and on a number of simulation experiments, and it is found competitive with existing approaches to variable selection."
  },
  {
    "objectID": "publications/2021_RepresentCIs/index.html",
    "href": "publications/2021_RepresentCIs/index.html",
    "title": "A framework based on statistical analysis and stakeholders’ preferences to inform weighting in composite indicators",
    "section": "",
    "text": "About\nComposite Indicators (CIs, a.k.a. indices) are increasingly used as they can simplify interpretation of results by condensing the information of a plurality of underlying indicators in a single measure. This paper demonstrates that the strength of the correlations between the indicators is directly linked with their capacity to transfer information to the CI. A measure of information transfer from each indicator is proposed along with two weight-optimization methods, which allow the weights to be adjusted to achieve either a targeted or maximized information transfer. The tools presented in this paper are applied to a case study for resilience assessment of energy systems, demonstrating how they can support the tailored development of CIs. These findings enable analysts bridging the statistical properties of the index with the weighting preferences from the stakeholders. They can thus choose a weighting scheme and possibly modify the index while achieving a more consistent (by correlation) index.\n\nSource code is available here."
  },
  {
    "objectID": "publications/2022_Battle/index.html",
    "href": "publications/2022_Battle/index.html",
    "title": "A comprehensive comparison of total-order estimators for global sensitivity analysis",
    "section": "",
    "text": "About\nSensitivity analysis helps identify which model inputs convey the most uncertainty to the model output. One of the most authoritative measures in global sensitivity analysis is the Sobol’ total-order index, which can be computed with several different estimators. Although previous comparisons exist, it is hard to know which estimator performs best since the results are contingent on the benchmark setting defined by the analyst (the sampling method, the distribution of the model inputs, the number of model runs, the test function or model and its dimensionality, the weight of higher order effects, or the performance measure selected). Here we compare several total-order estimators in an eight-dimension hypercube, where these benchmark parameters are treated as random parameters. This arrangement significantly relaxes the dependency of the results on the benchmark design. We observe that the most accurate estimators are from Razavi and Gupta, Jansen, or Janon/Monod for factor prioritization, and from Jansen, Janon/Monod, or Azzini and Rosatifor approaching the “true” total-order indices. The rest lag considerably behind. Our work helps analysts navigate myriad total-order formulae by reducing the uncertainty in the selection of the most appropriate estimator."
  },
  {
    "objectID": "publications/2022_WEFnexus/index.html",
    "href": "publications/2022_WEFnexus/index.html",
    "title": "The Water-Energy-Food Nexus Index: A Tool to Support Integrated Resource Planning, Management and Security",
    "section": "",
    "text": "About\nThe call for measuring synergies and trade-offs between water, energy, and food is increasing worldwide. This article presents the development and application of a country-level index that has been calculated for 181 nations using open databases. Following an assessment of 87 water-, energy-, and food-related indicators, 21 were selected to constitute the Water-Energy-Food (WEF) Nexus Index. In this article, the WEF Nexus Index is utilized to assess the Southern African Development Community, where it demonstrates that food security is an area of concern, while the potential for beneficially exploiting water resources and energy projects exists in several countries. Water for agriculture could be achieved through the drought-proofing of rainfed agriculture and systematic irrigation development, with energy as the critical enabler. Neither the composite indicator nor the WEF nexus approach is the panacea that will solve all the significant development or environmental challenges facing humanity. However, they could contribute to integrated resource management and policy-making and are complementary to the Sustainable Development Goals. In this study, the methodology set out by the Joint Research Centre’s Competence Center on Composite Indicators and Scoreboards has been followed. A set of visualizations associated with the WEF Nexus Index have been compiled in an interactive website, namely www.wefnexusindex.org.”\n\nSee interactive data exploration at the WEF Nexus Index homepage."
  }
]